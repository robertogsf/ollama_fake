# Configuración del servicio Ollama Fake
# Puerto donde se ejecutará el servicio (por defecto Ollama usa 11434)
PORT=11434

# Host donde se ejecutará
HOST=0.0.0.0

# Modo debug
DEBUG=False

# Modelo por defecto
DEFAULT_MODEL=llama2

# Si quieres conectar a una API externa real (opcional)
# EXTERNAL_API_URL=https://api.openai.com/v1/completions
# EXTERNAL_API_KEY=tu_api_key_aqui
