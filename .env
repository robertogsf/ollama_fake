# Configuración del servicio Ollama con IA Real
# Puerto donde se ejecutará el servicio (por defecto Ollama usa 11434)
PORT=11436

# Host donde se ejecutará
HOST=0.0.0.0

# Modo debug
DEBUG=false

# Modelo por defecto (usa qwen2.5:7b como modelo principal)
DEFAULT_MODEL=qwen2.5:7b

# Si quieres conectar a una API externa real (opcional)
# EXTERNAL_API_URL=https://api.openai.com/v1/completions
# EXTERNAL_API_KEY=tu_api_key_aqui

# Cache de modelos (donde se guardan los modelos descargados)
TRANSFORMERS_CACHE=/home/models/cache
HF_HOME=/home/models/hf_cache
